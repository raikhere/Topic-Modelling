{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e56f41-77f1-4880-a448-4d0db39e775e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parth/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-02-09 20:38:15.066433: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-09 20:38:16.200980: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64\n",
      "2023-02-09 20:38:16.201084: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64\n",
      "2023-02-09 20:38:16.201091: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-09 20:38:17.072344: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-09 20:38:17.072792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-09 20:38:17.072952: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3582a4b8-b395-4cbc-9838-b342ff38b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"smalldataset/newsdataset.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a151d167-ce52-411e-b727-61d454d974af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = spacy.load(\"en_core_web_trf\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c632975-7102-4856-984c-c40aa9a456c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"authors\",\"link\",\"date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4356d184-0014-4434-9de4-10cbf77d5b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450ca6c7-ca3f-4cfe-bad0-bfa567f92965",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00956037-9a5f-4839-8028-0e4bc8c8d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fullnews\"] = df[\"headline\"] +\" \"+ df[\"short_description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef87ebb-9059-40bc-9dbc-a121579415c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"category\",\"fullnews\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c97547-1db7-4fcc-890c-89243cc755b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64561f1c-0f42-4205-89ab-e15b10755527",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''dropcat = [\"RELIGION\", \"LATINO VOICES\", \"FIFTY\", \"WEIRD NEWS\", \"ENVIRONMENT\", \"QUEER VOICES\", \"GOOD NEWS\", \"MEDIA\", \"WEDDINGS\", \"GREEN\", \"TASTE\", \"WORLD NEWS\", \"IMPACT\", \"WOMEN\"]\n",
    "\n",
    "for i in dropcat:\n",
    "    df.drop(df.loc[df[\"category\"]==i].index, inplace=True, axis=0)\n",
    "\n",
    "df.loc[df[\"category\"]==\"COLLEGE\"] = [\"EDUCATION\"]\n",
    "df.loc[df[\"category\"]==\"ARTS & CULTURE\"] = [\"CULTURE & ARTS\"]\n",
    "df.loc[df[\"category\"]==\"ARTS\"] = [\"CULTURE & ARTS\"]\n",
    "df.loc[(df[\"category\"]==\"SCIENCE\") | (df[\"category\"]==\"TECH\")] = [\"SCIENCE & TECH\"]\n",
    "df.loc[df[\"category\"]==\"WORLDPOST\"] = [\"THE WORLDPOST\"]\n",
    "df.loc[df[\"category\"]==\"STYLE\"] = [\"STYLE & BEAUTY\"]\n",
    "df.loc[df[\"category\"]==\"MONEY\"] = [\"BUSINESS\"]\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.to_json(\"smalldataset/newsdataset.json\", lines=True, orient=\"records\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7568b03b-0186-4d81-bb04-9e725403af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_allowed_word_types = [\"PUNCT\", \"DET\", \"PART\", \"CCONJ\", \"SPACE\"]\n",
    "token_news = []\n",
    "count = 0\n",
    "\n",
    "for i in df[\"fullnews\"]:\n",
    "    tokenised = model(i)\n",
    "    smalltoken = [j.lemma_ for j in \n",
    "                  tokenised if j.pos_ not in not_allowed_word_types]\n",
    "    token_news.append(smalltoken)\n",
    "    count += 1\n",
    "    if count%5000==0:\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a01b2-c4bb-40bb-b466-a3bafe13aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokenizednews\"] = token_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8cf5f0c8-abb2-4568-af96-07392216c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43a2c110-c66d-4bdf-87a4-79b0e58ca720",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [w.lower()\n",
    "            for p in df[\"tokenizednews\"]\n",
    "            for w in p\n",
    "            if w.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02ac36-c932-4621-b45f-60ff064163ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"allowed_word_types = [\"J\"]\n",
    "\n",
    "\n",
    "for p in df[\"tokenizednews\"]:\n",
    "    pos = nltk.pos_tag(p)\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a372c-34bf-4e56-8f9c-236d95365627",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"print(len(all_words))\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "print(len(all_words))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50d89735-4d01-4905-855a-42fb5975e81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2918465\n",
      "69704\n"
     ]
    }
   ],
   "source": [
    "print(len(all_words))\n",
    "all_wordsfre = nltk.FreqDist(all_words)\n",
    "print(len(all_wordsfre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b60932-baa8-4ace-ad6f-30dd81c0f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wordsfre.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ab69dd6-340e-4e0a-843f-2a95568fe2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = [w[0] for w in all_wordsfre.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2066d6-4f89-4018-ba8a-558e91bf0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea6663-b189-479c-b512-fd7519d36ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92bd2b4-1136-475f-839c-6c4f797cc7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df.to_json(\"smalldataset/newsdatasetjson\", lines=True, orient=\"records\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37cb417-c7c8-4ba5-99ba-c4f44c892ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"smalldataset/word_features.pickle\",\"wb\")\n",
    "pickle.dump(word_features, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b51b7-698c-4928-a0b6-5ab9e2590039",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"smalldataset/word_features.pickle\", \"rb\")\n",
    "word_features = pickle.load(file)\n",
    "word_features = word_features[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548f0652-2f74-4d57-b495-43a72b62b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "countvector = CountVectorizer().fit(word_features)\n",
    "not_words = [i for i in word_features if i not in countvector.vocabulary_]\n",
    "\n",
    "for i in not_words:\n",
    "    word_features.remove(i)\n",
    "\n",
    "word_features = word_features[:8000]\n",
    "countvector = CountVectorizer().fit(word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74241f5-4416-4bc0-b130-64a94ac5e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoder.fit(np.array(df[\"category\"]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76acda4-1145-4169-8cf8-87646f2e4e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"smalldataset/newsdataset.json\", lines=True, chunksize=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b2abd9-8de3-48b6-b175-5a9cb5fedec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    features = countvector.transform(document).toarray()\n",
    "            \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b15d27-e79b-4c8e-a309-7b2cf989aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_features():\n",
    "    for data in df:\n",
    "\n",
    "        Y = encoder.transform(np.array(data[\"category\"]).reshape(-1,1)).toarray()\n",
    "\n",
    "        X = find_features(data[\"fullnews\"])\n",
    "\n",
    "        break\n",
    "        \n",
    "    return X, Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae6c7fa-5b9b-4456-8ba9-f833c5665688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.activations import relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62cafc32-1a00-4609-9954-dc9b42167e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de70b20e-43af-4444-8b1b-35ea2998c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional, Embedding, Conv1D, MaxPooling1D, SimpleRNN, LSTM, GRU, Dropout, Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61dd574-1a65-4532-bb7a-02ff3257fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\"model.h5\", save_best_only=True)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=8000),\n",
    "    keras.layers.Embedding(8000, 3),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1000, activation=\"LeakyReLU\"),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(800, activation=\"LeakyReLU\"),\n",
    "    keras.layers.Dense(400, activation=\"LeakyReLU\"),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(200, activation=\"LeakyReLU\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(20, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543e6e29-2481-448c-9a73-7d557e46a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential()\n",
    "model2.add(Input(shape=8000))\n",
    "model2.add(Embedding(8000, 3))\n",
    "model2.add(Bidirectional(LSTM(64, dropout=0.1, recurrent_dropout=0.10, activation='tanh', return_sequences=True)))\n",
    "model2.add(Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.20, activation='tanh', return_sequences=True)))\n",
    "model2.add(Bidirectional(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.20, activation='tanh', return_sequences=True)))\n",
    "model2.add(Conv1D(72, 3, activation='relu'))\n",
    "model2.add(MaxPooling1D(2))\n",
    "model2.add(SimpleRNN(64, activation='tanh', dropout=0.2, recurrent_dropout=0.20, return_sequences=True))\n",
    "model2.add(GRU(64, recurrent_dropout=0.20, recurrent_regularizer='l1_l2'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(20, activation='softmax'))\n",
    "model2.summary()\n",
    "\n",
    "\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41928047-9535-4668-9991-da3d1c1cb00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labencoder = LabelEncoder()\n",
    "#encoder.classes_ = np.load(\"labelencoder15.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a97d30b-1087-4ed5-b518-5dc2b401ae8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labencoder.fit(df[\"category\"])\n",
    "#np.save(\"smalldataset/labelencoder.npy\", labencoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d7475-6895-4324-8ee1-06c4d8967f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273b3dfb-e917-4813-8761-c787dba15e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"model.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b15de6-e3ec-4972-961b-c436e45b0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X, Y = get_features()\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "    X_test.append(x_test)\n",
    "    Y_test.append(y_test)\n",
    "    print(X.shape, Y.shape)\n",
    "    \n",
    "    \n",
    "    model2.fit(x_train, y_train, validation_split=0.2, epochs=5, batch_size=5, callbacks=checkpoint)\n",
    "    print(f\"Accuracy after {i} traindata\")\n",
    "    model2.evaluate(x_test,y_test)\n",
    "    #model = keras.models.load_model(\"model.h5\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d97f4-1251-4498-bae6-55d03607de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff2108f-6596-4c16-bfeb-d3ee11e05e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9420e1bb-9179-42bc-b8b9-c4ed677b4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d70a0b-f63e-4f52-a003-f903bfd538b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_arg = np.argmax(Y_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285fe704-7aa1-4f2e-a5b0-a8989ef335f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(Y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f39634e-99cd-453b-b047-8494dedf5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labencoder.classes_[y_pred_arg[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda3a46-5a8b-4278-a5e7-f9dc70f558e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae6469-e3c1-41fb-b460-31efa2baa9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7518e09-fdbf-4672-a3a7-d749f5184187",
   "metadata": {},
   "outputs": [],
   "source": [
    "labencoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16008c15-37a7-4772-9eb5-01df99dacfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c194cc2-5b8e-4319-844c-97b538fd5e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6bdbd7-fa8b-4f17-a22c-a25b2f497c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = kk.reshape(-1, 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ee87ec-7f58-4109-977f-bf268a88197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0485e6-a803-4f2d-b453-dffba9c15745",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = yy.reshape(-1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4824993-d116-421d-9779-274ffe6462db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(kk, yy, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ddf29b-f797-4cea-95fb-b1b4e7c76b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8a93c4-4142-42cb-85ae-e537b3b31a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab75e745-8132-4c87-bfd2-7d65bbc33ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f0370f-452b-475f-a833-287efeea0bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85056f0d-edec-4225-9487-4ca49417dc7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cda9e4-c592-4910-b921-f6012916c190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f473d6bb-9c2b-49ac-9325-8ffb2bea29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# model building imports\n",
    "from keras.layers import Embedding, Flatten, Dense, Dropout\n",
    "from keras.layers import Conv1D, SimpleRNN, Bidirectional, MaxPooling1D, GlobalMaxPool1D, LSTM, GRU, Input\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import L1L2\n",
    "#from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a16d35-156c-4e95-97d1-6094a0972e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>fullnews</th>\n",
       "      <th>tokenizednews</th>\n",
       "      <th>reducedtoken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>there were 2 mass shootings in texas last week...</td>\n",
       "      <td>[there, be, 2, mass, shooting, in, texas, last...</td>\n",
       "      <td>[mass, shooting, texas, last, week, tv, leave,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>will smith joins diplo and nicky jam for the 2...</td>\n",
       "      <td>[will, smith, join, diplo, nicky, jam, for, 20...</td>\n",
       "      <td>[smith, join, diplo, nicky, jam, 2018, world, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>hugh grant marries for the first time at age 5...</td>\n",
       "      <td>[hugh, grant, marry, for, first, time, at, age...</td>\n",
       "      <td>[hugh, grant, marry, first, time, age, 57, act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>jim carrey blasts 'castrato' adam schiff and d...</td>\n",
       "      <td>[jim, carrey, blast, castrato, adam, schiff, d...</td>\n",
       "      <td>[jim, carrey, blast, castrato, adam, schiff, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>julianna margulies uses donald trump poop bags...</td>\n",
       "      <td>[julianna, margulies, use, donald, trump, poop...</td>\n",
       "      <td>[julianna, margulies, use, donald, trump, poop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163747</th>\n",
       "      <td>SCIENCE &amp; TECH</td>\n",
       "      <td>rim ceo thorsten heins' 'significant' plans fo...</td>\n",
       "      <td>[rim, ceo, thorsten, heins, significant, plan,...</td>\n",
       "      <td>[rim, ceo, thorsten, heins, significant, plan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163748</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>maria sharapova stunned by victoria azarenka i...</td>\n",
       "      <td>[maria, sharapova, stun, by, victoria, azarenk...</td>\n",
       "      <td>[maria, sharapova, stun, victoria, azarenka, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163749</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>giants over patriots, jets over colts among  m...</td>\n",
       "      <td>[giant, over, patriot, jet, over, colt, among,...</td>\n",
       "      <td>[giant, patriot, jet, colt, among, improbable,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163750</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>aldon smith arrested: 49ers linebacker busted ...</td>\n",
       "      <td>[aldon, smith, arrest, 49ers, linebacker, bust...</td>\n",
       "      <td>[aldon, smith, arrest, 49ers, linebacker, bust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163751</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>dwight howard rips teammates after magic loss ...</td>\n",
       "      <td>[dwight, howard, rip, teammate, after, magic, ...</td>\n",
       "      <td>[dwight, howard, rip, teammate, magic, loss, h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163752 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              category                                           fullnews  \\\n",
       "0                CRIME  there were 2 mass shootings in texas last week...   \n",
       "1        ENTERTAINMENT  will smith joins diplo and nicky jam for the 2...   \n",
       "2        ENTERTAINMENT  hugh grant marries for the first time at age 5...   \n",
       "3        ENTERTAINMENT  jim carrey blasts 'castrato' adam schiff and d...   \n",
       "4        ENTERTAINMENT  julianna margulies uses donald trump poop bags...   \n",
       "...                ...                                                ...   \n",
       "163747  SCIENCE & TECH  rim ceo thorsten heins' 'significant' plans fo...   \n",
       "163748          SPORTS  maria sharapova stunned by victoria azarenka i...   \n",
       "163749          SPORTS  giants over patriots, jets over colts among  m...   \n",
       "163750          SPORTS  aldon smith arrested: 49ers linebacker busted ...   \n",
       "163751          SPORTS  dwight howard rips teammates after magic loss ...   \n",
       "\n",
       "                                            tokenizednews  \\\n",
       "0       [there, be, 2, mass, shooting, in, texas, last...   \n",
       "1       [will, smith, join, diplo, nicky, jam, for, 20...   \n",
       "2       [hugh, grant, marry, for, first, time, at, age...   \n",
       "3       [jim, carrey, blast, castrato, adam, schiff, d...   \n",
       "4       [julianna, margulies, use, donald, trump, poop...   \n",
       "...                                                   ...   \n",
       "163747  [rim, ceo, thorsten, heins, significant, plan,...   \n",
       "163748  [maria, sharapova, stun, by, victoria, azarenk...   \n",
       "163749  [giant, over, patriot, jet, over, colt, among,...   \n",
       "163750  [aldon, smith, arrest, 49ers, linebacker, bust...   \n",
       "163751  [dwight, howard, rip, teammate, after, magic, ...   \n",
       "\n",
       "                                             reducedtoken  \n",
       "0       [mass, shooting, texas, last, week, tv, leave,...  \n",
       "1       [smith, join, diplo, nicky, jam, 2018, world, ...  \n",
       "2       [hugh, grant, marry, first, time, age, 57, act...  \n",
       "3       [jim, carrey, blast, castrato, adam, schiff, d...  \n",
       "4       [julianna, margulies, use, donald, trump, poop...  \n",
       "...                                                   ...  \n",
       "163747  [rim, ceo, thorsten, heins, significant, plan,...  \n",
       "163748  [maria, sharapova, stun, victoria, azarenka, a...  \n",
       "163749  [giant, patriot, jet, colt, among, improbable,...  \n",
       "163750  [aldon, smith, arrest, 49ers, linebacker, bust...  \n",
       "163751  [dwight, howard, rip, teammate, magic, loss, h...  \n",
       "\n",
       "[163752 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0372cd01-aee6-485d-a592-102f417a7300",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e8d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [w.lower()\n",
    "            for p in df[\"tokenizednews\"]\n",
    "            for w in p\n",
    "            if w.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6401fce-55e3-407e-a89e-ce2602ab041e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2918465\n",
      "69704\n"
     ]
    }
   ],
   "source": [
    "print(len(all_words))\n",
    "all_wordsfre = nltk.FreqDist(all_words)\n",
    "print(len(all_wordsfre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f69254-e590-43c5-a1a8-3a3aa992e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = [w[0] for w in all_wordsfre.most_common()]\n",
    "countvector = CountVectorizer(stop_words=stop_words).fit(word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd6b4f4-e425-44c9-a964-f1c193ae66ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(countvector.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a819b452-10de-47b8-9a44-c90711d1f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "numwords = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d1ed8f-efd6-4915-9063-3d13ddb7a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"reducedtoken\"]\n",
    "tokenizer = Tokenizer(num_words=numwords, oov_token='<00V>') \n",
    "tokenizer.fit_on_texts(X)\n",
    "train_seq = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "19b7b72f-7ba9-4fa6-ae98-aed5d24aa024",
   "metadata": {},
   "outputs": [],
   "source": [
    "templist = []\n",
    "for i in df[\"tokenizednews\"]:\n",
    "    j = [k for k in i if k in vocab]\n",
    "    templist.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb4893-1f9d-4421-86a2-00dfc7a6eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padseq = pad_sequences(train_seq, maxlen=136)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d3b1d-a1bc-4279-8c98-27fc461b0aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoder.fit(np.array(df[\"category\"]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbdf54a-e56d-4e18-92ce-e5e96bf4666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = encoder.transform(np.array(df[\"category\"]).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35b92a39-8c49-453c-af69-89a42218a389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 136, 180)          1440000   \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 136, 400)          698400    \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 136, 200)          361200    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 27200)             0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 27200)            108800    \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 27200)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 800)               21760800  \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 800)              3200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 500)               400500    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 300)               150300    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 200)              800       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 20)                4020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,988,220\n",
      "Trainable params: 24,931,820\n",
      "Non-trainable params: 56,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\"model5.h5\", save_best_only=True)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=136),\n",
    "    keras.layers.Embedding(8000, 180),\n",
    "    keras.layers.GRU(400, return_sequences=True),\n",
    "    keras.layers.GRU(200, return_sequences=True),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(800, activation=\"LeakyReLU\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(500, activation=\"LeakyReLU\"),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(300, activation=\"LeakyReLU\"),\n",
    "    keras.layers.Dense(200, activation=\"LeakyReLU\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(20, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4547cd8-6893-4cd7-8c7b-12f356774572",
   "metadata": {},
   "outputs": [],
   "source": [
    "padseq_train, padseq_test, y_train, y_test = train_test_split(train_padseq, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dda0dc32-4596-44c2-9741-5fa560ddfe9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5240/5240 [==============================] - 267s 51ms/step - loss: 0.6917 - accuracy: 0.7914 - val_loss: 1.7026 - val_accuracy: 0.6057\n",
      "Epoch 2/5\n",
      "5240/5240 [==============================] - 275s 52ms/step - loss: 0.5943 - accuracy: 0.8187 - val_loss: 4.8275 - val_accuracy: 0.4074\n",
      "Epoch 3/5\n",
      "5240/5240 [==============================] - 273s 52ms/step - loss: 0.5096 - accuracy: 0.8424 - val_loss: 2.3851 - val_accuracy: 0.5710\n",
      "Epoch 4/5\n",
      "5240/5240 [==============================] - 281s 54ms/step - loss: 0.4341 - accuracy: 0.8636 - val_loss: 1.9123 - val_accuracy: 0.6089\n",
      "Epoch 5/5\n",
      "5240/5240 [==============================] - 277s 53ms/step - loss: 0.3720 - accuracy: 0.8827 - val_loss: 2.1302 - val_accuracy: 0.5967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0a6c1010f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padseq_train, y_train, epochs=5, validation_split=0.2, callbacks=checkpoint, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0ff3af6-0948-491f-9f5d-a2063c308f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 136, 180)          1440000   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 24480)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              24481000  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 800)               800800    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 400)               320400    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 200)               80200     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 200)              800       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                4020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,127,220\n",
      "Trainable params: 27,126,820\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7988d60-06f6-4e8c-825b-845623947c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 136, 180)          1440000   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 400)               698400    \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 800)               320800    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 800)              3200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 400)               320400    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 300)               120300    \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 200)              800       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 20)                4020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,968,120\n",
      "Trainable params: 2,966,120\n",
      "Non-trainable params: 2,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "131435ec-84d9-4345-afe2-e7868c6629b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e63609ff-da91-44f0-b4cd-b9491094aa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 684/2184 [========>.....................] - ETA: 24s - loss: 1.1777 - accuracy: 0.6607"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3325/3755507234.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadseq_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2038\u001b[0m                         ):\n\u001b[1;32m   2039\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2041\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[0;32m--> 133\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;31m# A new cache key will be built later when saving ConcreteFunction because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;31m# only active captures should be saved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     lookup_func_key, _ = function_context.make_cache_key((args, kwargs),\n\u001b[0m\u001b[1;32m    337\u001b[0m                                                          captures)\n\u001b[1;32m    338\u001b[0m     \u001b[0mconcrete_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookup_func_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/function_context.py\u001b[0m in \u001b[0;36mmake_cache_key\u001b[0;34m(args, captures)\u001b[0m\n\u001b[1;32m    146\u001b[0m   return function_cache.FunctionCacheKey(\n\u001b[1;32m    147\u001b[0m       \u001b[0mdummy_function_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       make_function_context()), signature_context.deletion_observer\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/function_context.py\u001b[0m in \u001b[0;36mmake_function_context\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m   return function_cache.FunctionContext(\n\u001b[0;32m--> 104\u001b[0;31m       EagerContext(parent_graph, device_functions, colocation_stack,\n\u001b[0m\u001b[1;32m    105\u001b[0m                    in_cross_replica_context, variable_policy, xla_context_id))\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(_cls, parent_graph, device_functions, colocation_stack, in_cross_replica_context, variable_policy, xla_context_id)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.evaluate(padseq_test, y_test, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acc7c9e6-fc54-4a4b-972a-99d94bf33228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 13:22:45.447842: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-07 13:22:45.448422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-07 13:22:45.448691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-07 13:22:45.448847: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-07 13:22:45.449174: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-07 13:22:45.449342: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-07 13:22:45.449499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-07 13:22:45.449631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2589 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "mod = keras.Sequential([\n",
    "    Input(shape=136),\n",
    "    Embedding(numwords, 180)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f27b4f5-e1dd-488f-b4cc-e5e6287140fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 3s 3ms/step - loss: 1.9992 - accuracy: 0.5975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9991627931594849, 0.5975390076637268]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(padseq_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cf32aef-544b-44fe-abfb-25b0dc76e5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,   38, 1216,   97,\n",
       "       1308, 2049,   97, 2049, 1216,   97,   10,  218,   18,  228,   20,\n",
       "        462,   40, 8487, 1906], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padseq_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a80a9ffe-aa7c-4687-b8d8-2511da79e792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 935us/step\n"
     ]
    }
   ],
   "source": [
    "k2 = mod.predict(train_padseq[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "167545cc-8f24-4726-88d3-10a172b7e1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03533294,  0.00897727, -0.02590462, ...,  0.01746919,\n",
       "       -0.03165217,  0.02695059], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edccbf3e-21bd-448b-8da1-1badaf71bd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03533294,  0.00897727, -0.02590462, ..., -0.04599941,\n",
       "        0.02142418,  0.02448538], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k2.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2acbb96-745d-46d1-8144-81fe7294297b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0e2d57f-a2e5-4948-a53f-3f767abd86bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([len(i) for i in train_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed8d1fd5-ba04-4e17-b841-5eaf294bb733",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "297d78ac-e04d-417a-a69a-001566dd206d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/parth/miniconda3/lib/python3.10/site-packages/keras/engine/training.py\", line 1820, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/parth/miniconda3/lib/python3.10/site-packages/keras/engine/training.py\", line 1804, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/parth/miniconda3/lib/python3.10/site-packages/keras/engine/training.py\", line 1792, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/parth/miniconda3/lib/python3.10/site-packages/keras/engine/training.py\", line 1756, in test_step\n        y_pred = self(x, training=False)\n    File \"/home/parth/miniconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/parth/miniconda3/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 8000), found shape=(None, 136)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6834/3837909947.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadseq_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/parth/miniconda3/lib/python3.10/site-packages/keras/engine/training.py\", line 1820, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/parth/miniconda3/lib/python3.10/site-packages/keras/engine/training.py\", line 1804, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/parth/miniconda3/lib/python3.10/site-packages/keras/engine/training.py\", line 1792, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/parth/miniconda3/lib/python3.10/site-packages/keras/engine/training.py\", line 1756, in test_step\n        y_pred = self(x, training=False)\n    File \"/home/parth/miniconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/parth/miniconda3/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 8000), found shape=(None, 136)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(padseq_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "077ee984-11a4-48ba-ac6a-18262ebc0951",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.backend.tensorflow_backend'; 'keras.backend' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13739/1792549937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SESSION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.backend.tensorflow_backend'; 'keras.backend' is not a package"
     ]
    }
   ],
   "source": [
    "import keras.backend.tensorflow_backend\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "if keras.backend.tensorflow_backend._SESSION:   \n",
    "   tf.reset_default_graph() \n",
    "   keras.backend.tensorflow_backend._SESSION.close()\n",
    "   keras.backend.tensorflow_backend._SESSION = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b078881-9c72-43ec-8005-ab64dd1683f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
